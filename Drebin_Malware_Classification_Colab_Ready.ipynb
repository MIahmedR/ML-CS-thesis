{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17f08cdd",
   "metadata": {},
   "source": [
    "# ðŸ§  Drebin Android Malware Classification  \n",
    "**Using Feature Selection, PCA, LazyPredict & Cross-Validation**\n",
    "\n",
    "This Colab-ready notebook presents a clean, research-quality pipeline for classifying Android malware using the Drebin dataset.  \n",
    "It includes:\n",
    "- Feature selection with Random Forest\n",
    "- Dimensionality reduction using PCA\n",
    "- Model benchmarking using LazyPredict\n",
    "- Cross-validation on the best classifier\n",
    "- Class imbalance visualization\n",
    "- Sparse feature pruning\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819c5e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lazypredict scikit-learn xgboost pandas numpy seaborn matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2d0096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel, VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.utils import all_estimators\n",
    "from google.colab import drive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f017b191",
   "metadata": {},
   "source": [
    "## ðŸ“‚ Load Drebin Dataset from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7628479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')\n",
    "dataset_path = '/content/drive/My Drive/drebin.csv'\n",
    "data = pd.read_csv(dataset_path)\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58f8816",
   "metadata": {},
   "source": [
    "## ðŸ§¼ Data Preprocessing and Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e5ccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop or encode object columns\n",
    "object_cols = data.select_dtypes(include='object').columns.tolist()\n",
    "print(\"Object columns:\", object_cols)\n",
    "\n",
    "# Drop non-informative ID-like columns\n",
    "data.drop(columns=[col for col in object_cols if col != 'class'], inplace=True)\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['class'])\n",
    "y = data['class']\n",
    "\n",
    "# Visualize class distribution\n",
    "sns.countplot(x=y)\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# Encode target\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Fill NA and force numeric\n",
    "X = X.apply(pd.to_numeric, errors='coerce').fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00da2200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop classes with only 1 sample (to prevent classifier issues)\n",
    "class_counts = pd.Series(y).value_counts()\n",
    "minority_classes = class_counts[class_counts < 2].index.tolist()\n",
    "for cls in minority_classes:\n",
    "    indices_to_drop = np.where(y == cls)[0]\n",
    "    X = X.drop(index=indices_to_drop)\n",
    "    y = np.delete(y, indices_to_drop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b044f0b",
   "metadata": {},
   "source": [
    "## ðŸ” Train/Test Split, Feature Selection, PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62791c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Remove low-variance (nearly constant) features\n",
    "vt = VarianceThreshold(threshold=0.0001)\n",
    "X_train = vt.fit_transform(X_train)\n",
    "X_test = vt.transform(X_test)\n",
    "\n",
    "# Feature selection\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "selector = SelectFromModel(rf, threshold='median')\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "X_test_scaled = scaler.transform(X_test_selected)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('PCA Explained Variance')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3640aba9",
   "metadata": {},
   "source": [
    "## ðŸ¤– LazyPredict Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c7df62",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LazyClassifier(verbose=0, ignore_warnings=True)\n",
    "models, predictions = clf.fit(X_train_pca, X_test_pca, y_train, y_test)\n",
    "\n",
    "top_models = models.sort_values(\"Accuracy\", ascending=False).head(10)\n",
    "print(\"Top 10 Models by Accuracy:\\n\")\n",
    "print(top_models)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=top_models.index, y=top_models['Accuracy'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Top 10 Classifiers by Accuracy (LazyPredict)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393784cd",
   "metadata": {},
   "source": [
    "## ðŸ§ª Best Model Evaluation with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a84144",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = top_models.index[0]\n",
    "print(f\"Evaluating: {best_model_name}\")\n",
    "\n",
    "model_dict = dict(all_estimators(type_filter='classifier'))\n",
    "BestModelClass = model_dict[best_model_name]\n",
    "best_model = BestModelClass()\n",
    "best_model.fit(X_train_pca, y_train)\n",
    "y_pred = best_model.predict(X_test_pca)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f\"Confusion Matrix: {best_model_name}\")\n",
    "plt.show()\n",
    "\n",
    "# Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(best_model, X_train_pca, y_train, cv=cv, scoring='accuracy')\n",
    "print(f\"Cross-Validation Scores: {scores}\")\n",
    "print(f\"Mean Accuracy: {scores.mean():.4f} Â± {scores.std():.4f}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
